# Transfer Learning with PyTorch
Starting with a model pretrained on a large dataset (e.g., ImageNet, COCO) and fine-tuning it on a smaller, task-specific dataset. This technique is crucial when labeled data is limited and helps improve model performance by leveraging learned features from large, general datasets.

A simple endâ€‘toâ€‘end example demonstrating how to fineâ€‘tune pretrained vision models on your own datasets:

* **Image Classification** using a ResNetâ€‘50 pretrained on ImageNet
* **Object Detection** using a Faster Râ€‘CNN (ResNetâ€‘50â€‘FPN backbone) pretrained on COCO



## ğŸ” Project Structure

```
.
â”œâ”€â”€ transfer_learning.py   # main training script
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # this file
```


## ğŸ“¦ Setup

1. **Clone & install**

   ```bash
   git clone <repo_url>
   cd Neural-Transfer-Learning
   pip install -r requirements.txt
   ```

2. **Download datasets** (make sure these are mounted under `/kaggle/input` or adjust paths):

   * **ImageNet Val**

     ```
     /kaggle/input/imagenet-object-localization-challenge/
         â”œâ”€â”€ ILSVRC/Data/CLS-LOC/val    # images
         â”œâ”€â”€ LOC_val_solution.csv       # labels
         â””â”€â”€ LOC_synset_mapping.txt     # synsetâ†’name map
     ```
   * **COCO2017**

     ```
     /kaggle/input/coco2017/
         â”œâ”€â”€ train2017/                 # train images
         â”œâ”€â”€ val2017/                   # val images
         â””â”€â”€ annotations/
             â”œâ”€â”€ instances_train2017.json
             â””â”€â”€ instances_val2017.json
     ```


## ğŸš€ Usage

```bash
python transfer_learning.py
```

By default this will:

1. **Fineâ€‘tune ResNet50** on the ImageNet validation set (3 epochs, classification)
2. **Fineâ€‘tune Fasterâ€¯Râ€‘CNN** on COCO2017 (2 epochs, detection)

Modify the topâ€level `train_imagenet_classification` / `train_coco_detection` calls for different hyperparameters (epochs, batch size, learning rate, etc.).


## ğŸ› ï¸ Requirements

```txt
torch
torchvision
pycocotools
pandas
Pillow
```

Install via:

```bash
pip install torch torchvision pycocotools pandas pillow
```


## ğŸ“– About Transfer Learning

* **Why?**
  When you have **limited labeled data**, starting from a model pretrained on a large, generic dataset (e.g., ImageNet or COCO) lets you leverage its learned representations. Fineâ€‘tuning adapts those features to your specific taskâ€”often yielding better accuracy and faster convergence than training from scratch.

* **How?**

  1. Load a pretrained backbone+head.
  2. Replace the final classification/regression layers to match your target labels.
  3. Train (often with a lower learning rate) on your smaller dataset.

